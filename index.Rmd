---
title: "Simultaneous Directional Inference"
date: "`r Sys.Date()`"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Vignette Title}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r setup, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```


Supplementary R code for reproducing the examples in the paper ``Simultaneous Directional Inference''. 

## Set up

Install the latest version of the [`nplus `](https://github.com/aldosolari/nplus)  R package:

```{r, results='hide', message=F, warning=F, error=F, comment=NA}
devtools::install_github("aldosolari/nplus")
```

## Introduction

We consider the problem of inference on the signs of $n>1$ parameters. 
Let $\theta = (\theta_1,\ldots,\theta_n)$ be a vector of $n$ unknown real-valued parameters. For any $I\subseteq \{1,\ldots,n\}$, let $n^+(I)$ and  $n^-(I)$ be the number of parameters $\theta_i$, $i \in I$ with positive values and negative values, respectively:
$$n^+(I) = |\{ i \in I : \theta_i > 0 \}|, \quad n^-(I) = |\{ i \in I : \theta_i < 0 \}|.
$$
For simplicity of notation, we use $n^+$ and $n^-$ instead of $n^+(\{1,\ldots,n\})$ and  $n^-(\{1,\ldots,n\})$.

Our first goal is to provide lower bounds $\ell_{\alpha}^{+}(I)$ and $\ell_{\alpha}^{-}(I)$  for  $n^+(I)$ and  $n^-(I)$ such that 
$$
\mathrm{pr}_{\theta}\Big(
n^{+}(I) 
\geq 
\ell_{\alpha}^{+}(I),\,\,
n^{-}(I) 
\geq 
\ell_{\alpha}^{-}(I),
 \mathrm{\,\,for\,\,all\,\,}I  \Big) \geq 1- \alpha.
$$
It is worth noting that once we have obtained the confidence lower bounds on the number of positive and negative parameters, we can automatically derive the corresponding upper bounds, i.e. if $n^{+}(I) \geq \ell_\alpha^+(I), n^{-}(I) \geq \ell_\alpha^-(I)$ holds, then also $n^{+}(I) \leq  |I| - \ell^-_\alpha(I), n^{-}_\alpha(I) \leq |I| - \ell^{+}_\alpha(I)$ holds.  

For finding $\ell_{\alpha}^{+}(I)$ and $\ell_{\alpha}^{-}(I)$, we use the *directional closed testing* (DCT) procedure: first, 
select from each pair 
$$
 H_i^-: \theta_i \leq 0, \qquad
 H_i^+: \theta_i \geq 0.
$$

the hypothesis to test. Let $p_i$ and $q_i=1-p_i$ be the  $p$-values for $H_i^-$ and $H_i^+$, respectively. We select $H_i^-$ if $p_i \leq 1/2$ and $H_i^+$ if $p_i > 1/2$.  

Second, on the selected $n$ one-sided
hypotheses, apply the closed testing procedure at level $\alpha$. 
Of course, the second step has to
take care to adjust for the first step of selection from the same data. 


In some settings it is enough to infer on positive and non-positive findings, i.e., the interest is only in lower bounds on $n^+(I)$ and on $n^-(I)+n^0( I)$, where $n^0( I) = | I|-n^+(I)-n^-(I) = |i\in I: \theta_i = 0|$.
Thus we would like to provide lower bounds $\bar{\ell}_{\alpha}^{+}(I)$ and $\bar{\ell}_{\alpha}^{-}(I)$  for  $n^+(I)$ and  $n^-(I)+n^0(I)$ such that
$$
  \mathrm{pr}_{\theta}\Big(
n^{+}(I) 
\geq 
\bar{\ell}_{\alpha}^{+}(I),\,\,
n^{-}(I)+n^{0}(I) 
\geq 
\bar{\ell}_{\alpha}^{-}(I),
 \mathrm{\,\,for\,\,all\,\,}I  \Big) \geq 1- \alpha.$$
For finding $\bar{\ell}_{\alpha}^+(I)$ and $\bar{\ell}_{\alpha}^-(I)$ we use the *partitioning principle* to the $2^n$ orthants defined by $\theta_i \in \{\theta_i\leq 0, \theta_i>0\}, i=1,\ldots, n$. It turns out that the bounds obtained through the partitioning principle with *adaptive tests* uniformly improves upon the DCT bounds:
$\bar{\ell}_{\alpha}^{+}(I)\geq \ell_{\alpha}^{+}(I)$, $\bar{\ell}_{\alpha}^{-}(I)\geq \ell_{\alpha}^{-}(I)$. 

## Subgroup Analysis

The data analysed in Gail and Simon (1985) consists of the difference in disease-free survival probabilities at 3 years for breast cancer patients who underwent a PFT treatment compared to those who received a PF treatment. The study includes a total of 1260 patients divided in $n=4$ subgroups, classified based on age and progesterone receptor levels. Table 2 in Gail and Simon
(1985) reports for each subgroup the difference $d_i$ and the corresponding standard error $s_i$.

```{r}
d_i = c(.163, -.114, -.047, -.151)
s_i = c(.0788, .0689, .0614, .0547)
p_right_tail = 1-pnorm(d_i/s_i)
```

The right-sided $p$-value for $H_i^-$ is calculated using the large-sample normal approximation. 
Based on the right-sided $p$-values, we select the hypotheses $H_1^-$, $H_2^+$, $H_3^+$, $H_4^+$ and we adjust for the selection the corresponding $p$-values:

```{r}
n = length(p_right_tail)
S = rep("+",n)
S[p_right_tail <= 0.5] <- "-" 
hyp_selected <- paste0("H",paste0(1:n,S))
p_selected <- 2*pmin(p_right_tail, 1-p_right_tail)
names(p_selected) <- hyp_selected
p_selected
```

Function to compute the power set of a set:

```{r}
powset <- function(set) { 
  n <- length(set)
  masks <- 2^(1:n-1)
  lapply( 1:2^n-1, function(u) set[ bitwAnd(u, masks) != 0 ] )
}
```

Function to compute the $p$-value of the Simes local test:

```{r}
p_combi_test <- function(x) {  min(sort(x)*length(x)/(1:length(x)))  }
```

Computing the $p$-value for each intersection hypothesis by using the Simes local test:

```{r, message=F, warning=F, error=F, comment=NA}
res = round(unlist(
  lapply(powset(1:n), function(x) p_combi_test(p_selected[x]))
),4)
names(res) <- powset(hyp_selected)
res
```

Adjusted $p$-values by closed testing:
```{r}
res_ct = res
closure = powset(1:n)
for (k in 1:length(closure))
res_ct[[k]] = max(res[sapply(1:length(closure), function(i) all(closure[[k]] %in% closure[[i]]))]) 
res_ct
```


Partitioning procedure with adaptive tests:
```{r}
Sc = rep("-",n)
Sc[p_right_tail <= 0.5] <- "+" 
hyp_part <- powset(1:n)
for (i in 1:length(hyp_part)){
hyp_part[[i]] <- Sc
hyp_part[[i]][ powset(1:n)[[i]] ] <- S[ powset(1:n)[[i]] ]
}
res_part <- res
names(res_part) <- hyp_part
res_part
```



$95\%$ confidence lower and upper bounds $\bar{\ell}_{\alpha}^{+}$ and $n - \bar{\ell}_{\alpha}^{-}$ for $n^+$  by using the partitioning procedure with adaptive Simes' tests:
```{r}
library(nplus)
nplus_bound(p_right_tail, alpha=0.05, method="Simes")
```
Index set of positive discoveries (i.e. $i:\theta_i >0$) and non-positive discoveries ($i:\theta_i \leq 0$) with familywise error rate control at level $\alpha$:
```{r}
nplus_fwer(p_right_tail, alpha=0.05, method="Simes")
```

Gail, M. and Simon, R. (1985). Testing for qualitative interactions between treatment
effects and patient subsets. Biometrics, pages 361â€“372.


## Enhancing meta-analysis

We consider the  data in Konstantopoulos (2011), where the  effect of a modified school calendar (with more frequent but shorter breaks) on student achievement is examined. The meta-analysis uses studies of $n=56$ schools in 11 districts.  The experimental design is a two-group comparison (modified calendar vs traditional
calendar) which involves computing the standardized mean difference
$X_i \sim N(\theta_i,1)$, where $\theta_i>0$ indicates a positive effects, i.e. a higher level of achievement in the
group following the modified school calendar.

We analyze the data by providing the lower and upper bounds on the number of studies with positive effect in all schools and in the (data-driven) top $k$ schools.

Importing data from the R package `metafor `:

```{r, results='hide', message=F, warning=F, error=F, comment=NA}
require("metafor") || install.packages("metafor")
```

```{r, message=F, warning=F, error=F, comment=NA}
dat <- get(data(dat.konstantopoulos2011))
x <- as.vector(dat$yi / sqrt(dat$vi))
n <- length(x)
p_right_tail <- pnorm(x, lower.tail = FALSE)
```

Partitioning procedure with adaptive tests (P) and directional closed testing (DCT) procedures: $(1-\alpha)=95\%$ confidence bounds [`LO+`,`UP+`] on the number of studies with positive effects along with the number of positive discoveries (`D+`) and $95\%$ confidence bounds [`LO-`,`UP-`] on the number of studies with nonpositive/negative effects along with the number of nonpositive/negative discoveries (`D-`) for different combining functions: Fisher, Simes, modified Simes and adaptive LRT:

```{r}
alpha = 0.05
S_minus = which(p_right_tail <= 0.5)
S_plus = which(p_right_tail > 0.5)
RES = matrix(NA, ncol=8, nrow=8)
RES[,1] = rep(c("Fisher","Simes","mSimes","ALRT"),each=2)
RES[,2] = rep(c("P","DCT"),4)
colnames(RES) <- c("Local test","Procedure", "LO+","UP+","D+", "LO-","UP-","D-")
for (i in 1:4){
 res_bound <- nplus_bound(p_right_tail, method=RES[i,1], alpha=alpha)
 res_d <- nplus_fwer(p_right_tail, method=RES[i,1], alpha=alpha)
 res_dct_lo <- min(which(nplus_pvalue(p_right_tail, method=RES[i,1], ix = S_minus) > alpha)) - 1
 res_dct_up <- n - min(which(nplus_pvalue(p_right_tail, method=RES[i,1], ix = S_plus) > alpha)) - 1 
 RES[(2*i)-1,3] <- res_bound$lo
 RES[2*i,3] <- res_dct_lo
 RES[(2*i)-1,4] <- res_bound$up
 RES[2*i,4] <- res_dct_up
 RES[(2*i)-1,5] <- RES[2*i,5] <- length(res_d$positive)
 RES[(2*i)-1,6] <- n-res_bound$up
 RES[2*i,6] <- n - res_dct_up
 RES[(2*i)-1,7] <- n-res_bound$lo
 RES[2*i,7] <- n - res_dct_lo
 RES[(2*i)-1,8] <- RES[2*i,8] <- length(res_d$nonpositive)
}
knitr::kable(RES)
```






Discoveries by Guo and Romano (2015) procedures with FWER and FDR control at $\alpha=0.05$ level:

```{r}
GuoRomano2015 <- function(p_right_tail, alpha=0.05){
  
  p <- p_right_tail
  n <- length(p)
  sp <- sort( c(p,1-p), index.return=TRUE )
  
  FWER_id <- max(which(cumsum( sp$x <= alpha / (n - 1:n + 1L + alpha) )==1:(2*n)))
  FWER_REJ <- rep(FALSE,2*n)
  if (is.finite(FWER_id)) FWER_REJ[1:FWER_id] <- TRUE
  FWER_NONPOS <-  1:n %in% sp$ix[FWER_REJ]
  FWER_POS <-  (n+1):(2*n) %in% sp$ix[FWER_REJ]
  
  FDR_id <- max(which(sp$x <= alpha * (1:n) / n))
  FDR_REJ <- rep(FALSE,2*n)
  if (is.finite(FDR_id)) FDR_REJ[1:FDR_id] <- TRUE
  FDR_NONPOS <-  1:n %in% sp$ix[FDR_REJ]
  FDR_POS <-  (n+1):(2*n) %in% sp$ix[FDR_REJ]
  
  return(list(FWER = list(n_discoveries_positive = sum(FWER_NONPOS), n_discoveries_nonpositive = sum(FWER_POS)), 
              FDR= list(n_discoveries_positive = sum(FDR_NONPOS), n_discoveries_nonpositive = sum(FDR_POS))))
  
}
GuoRomano2015(p_right_tail, alpha = alpha)
```

Konstantopoulos, S. (2011). Fixed effects and variance components estimation in three-level
meta-analysis. Research Synthesis Methods, 2(1):61â€“76.

Guo, W. and Romano, J. P. (2015). On stepwise control of directional errors under independence and some dependence. Journal of Statistical Planning and Inference, 163:21â€“33.

